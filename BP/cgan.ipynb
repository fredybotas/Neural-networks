{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ganimedes/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "\n",
    "input_encoder = Input(shape=(28, 28, 1))\n",
    "input_decoder = Input(shape=(4, 4, 4))\n",
    "\n",
    "with open('decoder.json', 'r') as f:\n",
    "    decoder = model_from_json(f.read())\n",
    "    decoder.load_weights(\"decoder.h5\")\n",
    "    \n",
    "with open('encoder.json', 'r') as f:\n",
    "    encoder = model_from_json(f.read())\n",
    "    encoder.load_weights(\"encoder.h5\")\n",
    "    \n",
    "with open('autoencoder.json', 'r') as f:\n",
    "    autoencoder = model_from_json(f.read())\n",
    "    autoencoder.load_weights(\"autoencoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADqCAYAAAAlBtnSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xm8VfP+x/HPkUQimtFcSkmk0ZCxa56VKa55zMU1xI9c3UzXcHNDImPKkCGKkiFTIhSVKCkqpVFJIcL5/eHh4/39dvbudNp7n7P2eT3/+qy+37POstf5rrX28v18PwWFhYUGAAAAAACAsm2j0j4AAAAAAAAArBsvcQAAAAAAABKAlzgAAAAAAAAJwEscAAAAAACABOAlDgAAAAAAQALwEgcAAAAAACABeIkDAAAAAACQALzEAQAAAAAASABe4gAAAAAAACTAxuvTuaCgoDBbB4L0CgsLCzKxH85hqVpaWFhYMxM74jyWHsZiXmAs5gHGYl5gLOYBxmJeYCzmAcZiXijWWGQmDpA7c0r7AACYGWMRKCsYi0DZwFgEyoZijUVe4gAAAAAAACQAL3EAAAAAAAASgJc4AAAAAAAACcBLHAAAAAAAgATgJQ4AAAAAAEAC8BIHAAAAAAAgAXiJAwAAAAAAkAC8xAEAAAAAAEiAjUv7AFA+XX755R5vttlmQVvr1q097tq1a8p9DBgwwOP33nsvaBs8ePCGHiIAAAAAAGUKM3EAAAAAAAASgJc4AAAAAAAACcBLHAAAAAAAgARgTRzkzNChQz1Ot9aN+v3331O2nXvuuR536dIlaHvrrbc8njt3bnEPEaWsWbNmwfb06dM9vvjiiz2+6667cnZM5dnmm2/u8W233eaxjj0zs4kTJ3rcrVu3oG3OnDlZOjoAAIDSsfXWW3tcv379Yv1M/Ez0z3/+0+OpU6d6PGPGjKDf5MmTS3KIyGPMxAEAAAAAAEgAXuIAAAAAAAAkAOlUyBpNnzIrfgqVptC8/PLLHjdu3Djod/jhh3vcpEmToK179+4e33zzzcX6vSh9bdq0CbY1nW7evHm5Ppxyb5tttvH47LPP9jhOc2zbtq3Hhx12WNDWv3//LB0d1K677urxsGHDgraGDRtm7fcecMABwfa0adM8/vrrr7P2e7Fueo80MxsxYoTHF154ocf33ntv0O+3337L7oHloVq1ann81FNPefzuu+8G/QYOHOjx7Nmzs35cf6patWqwvddee3k8evRoj9esWZOzYwKS4NBDD/X4iCOOCNr22Wcfj5s2bVqs/cVpUg0aNPC4UqVKKX+uQoUKxdo/yg9m4gAAAAAAACQAL3EAAAAAAAASgHQqZFS7du08Pvroo1P2+/TTTz2OpycuXbrU41WrVnm8ySabBP3Gjx/v8c477xy0Va9evZhHjLJkl112CbZ/+OEHj5977rlcH065U7NmzWB70KBBpXQkWF8HHnigx+mmZGdanLJzxhlneHzCCSfk7DjwB7333XPPPSn73X333R4/9NBDQdtPP/2U+QPLM1qVxix8ptHUpUWLFgX9SiuFSisImoXXek2HnTlzZvYPLGG23HLLYFtT9Fu1auVxXCWV1LSyTZdh6NGjh8eaOm5mttlmm3lcUFCwwb83rsIKlBQzcQAAAAAAABKAlzgAAAAAAAAJwEscAAAAAACABCjVNXHiktOah/jNN98EbatXr/b4scce83jhwoVBP/J5S5eWJI5zRzVnXNdvWLBgQbH2fdlllwXbLVu2TNl35MiRxdonSp/mlGvZWzOzwYMH5/pwyp2LLrrI46OOOipo69Chw3rvT0vXmplttNFf/69g8uTJHr/99tvrvW+ENt74r1v4IYccUirHEK+1cemll3q8+eabB226xhWyQ8df3bp1U/Z74oknPNbnK6RWo0YNj4cOHRq0VatWzWNdi+gf//hH9g8shV69enncqFGjoO3cc8/1mOfmtXXv3t3jG2+8MWirV69ekT8Tr53z7bffZv7AkDF6fbz44ouz+rumT5/usX4XQuZoiXe9VpuFa7RqWXgzs99//93je++91+Nx48YF/cridZKZOAAAAAAAAAnASxwAAAAAAIAEKNV0qltvvTXYbtiwYbF+TqeBrly5MmjL5TS1efPmeRz/t0yYMCFnx1GWvPDCCx7r1Daz8FwtW7Zsvfcdl6utWLHieu8DZc8OO+zgcZx+EU9ZR+bdcccdHuu00pI65phjUm7PmTPH4+OPPz7oF6flYN323Xdfj3fbbTeP4/tRNsWlljXNtXLlykEb6VSZF5eTv+aaa4r1c5qqWlhYmNFjyle77rqrx/GUfNWnT58cHM3adtxxx2BbU9Cfe+65oI1769o0veZ///ufx9WrVw/6pRovd911V7Ct6eEleeZF8cSpM5oapSkxo0ePDvr9/PPPHq9YscLj+D6lz6WvvPJK0DZ16lSP33//fY8//vjjoN9PP/2Ucv8oPl1+wSwcY/qsGf9NFFfHjh09/vXXX4O2zz//3ON33nknaNO/uV9++aVEv7skmIkDAAAAAACQALzEAQAAAAAASABe4gAAAAAAACRAqa6JoyXFzcxat27t8bRp04K2Fi1aeJwuL7lTp04ef/311x6nKglYFM2DW7JkicdaPjs2d+7cYLu8romjdP2Lkrriiis8btasWcp+mota1DbKrp49e3oc/80wjrJj1KhRHmsJ8JLSUqqrVq0K2ho0aOCxlrn94IMPgn4VKlTY4OPId3E+uJaJnjVrlsc33XRTzo7pyCOPzNnvwtp22mmnYLtt27Yp++qzzUsvvZS1Y8oXtWrVCraPPfbYlH3PPPNMj/W5Mdt0HZzXXnstZb94TZx4PUmYXX755R5ryfjiitd5O+iggzyOy5Tr+jm5XEMjX6Rbp2bnnXf2WEtLx8aPH++xfq+cPXt20K9+/foe61qoZplZRxBr0/cBPXr08DgeY1tuuWWRPz9//vxge+zYsR5/9dVXQZt+B9G1GTt06BD002vCIYccErRNnjzZYy1Tnm3MxAEAAAAAAEgAXuIAAAAAAAAkQKmmU40ZMybttopLw/0pLm+6yy67eKzTotq3b1/s41q9erXHM2bM8DhO8dKpVTqVHRvmsMMO81hLdW6yySZBv8WLF3v8f//3f0Hbjz/+mKWjw4Zq2LBhsN2uXTuPdbyZUYoxU/bee+9gu3nz5h7rdODiTg2Op4vqdGYt1Wlmtt9++3mcrvzx+eef7/GAAQOKdRzlTa9evYJtnVKuU/fjlLZM03tf/LfF9PLcSpfiE4vTDpDef//732D75JNP9lifL83Mnn766ZwcU6xz584e165dO2h75JFHPB4yZEiuDikxNNXXzOz0008vst+UKVOC7UWLFnncpUuXlPuvWrWqx5qqZWb22GOPebxw4cJ1H2w5Fz//P/744x5r+pRZmE6cLsVQxSlUKl4uA5l33333BduaBpeuXLi+N/jkk088vvrqq4N++r0+tvvuu3usz6EPPfRQ0E/fL+g1wMysf//+Hj/77LMeZzu1lpk4AAAAAAAACcBLHAAAAAAAgAQo1XSqTFi+fHmw/cYbbxTZL12qVjo6VTlO3dKpW0OHDi3R/rE2Ta+Jp1Aq/czfeuutrB4TMidOv1C5rOqR7zRt7cknnwza0k1PVVotTKeI/vvf/w76pUtf1H2cc845HtesWTPod+utt3q86aabBm133323x2vWrFnXYeeVrl27ehxXRJg5c6bHuazkpmlxcfrUm2++6fF3332Xq0Mqt/baa6+UbXHVm3TpjFhbYWFhsK1/6998803Qls0KQ5tttlmwrakCF1xwgcfx8Z5xxhlZO6Z8oOkRZmZbbLGFx1rNJn5m0fvTiSee6HGcwtGkSROP69SpE7QNHz7c44MPPtjjZcuWFevYy4MqVap4HC+ZoMsuLF26NGi7/fbbPWZphbIjfq7TqlBnnXVW0FZQUOCxfi+IU+1vu+02j0u6/EL16tU91iqpvXv3Dvrpsi5xKmZpYSYOAAAAAABAAvASBwAAAAAAIAF4iQMAAAAAAJAAiV8TJxtq1arl8T333OPxRhuF77y0/DV5rCX3/PPPB9sHHHBAkf0effTRYDsut4tk2GmnnVK26boo2DAbb/zX5b24a+DEa0udcMIJHsd558Wla+LcfPPNHvft2zfoV7lyZY/jv4MRI0Z4PGvWrBIdR1J169bNY/2MzML7U7bpGkvdu3f3+Lfffgv63XDDDR6Xt/WLckVLomoci9cImDRpUtaOqbw59NBDg20t365rQcVrOBSXrsOyzz77BG2dOnUq8meeeeaZEv2u8qpSpUrBtq4pdMcdd6T8OS1X/PDDD3us12ozs8aNG6fch67Vks31lJLsqKOO8viqq64K2rTsd+fOnYO2FStWZPfAUCLxdeyKK67wWNfAMTObP3++x7o27QcffFCi361r3dSrVy9o0++Wo0aN8jheB1fFxzt48GCPc7kWIDNxAAAAAAAAEoCXOAAAAAAAAAlAOlURevTo4bGWwY3LmX/++ec5O6Z8s80223gcTwfXKa6awqHT9M3MVq1alaWjQ6bp9O/TTz89aPv44489fvXVV3N2TPiDlqaOS9KWNIUqFU2L0pQcM7P27dtn9HclVdWqVYPtVKkTZiVP1SgJLQ+v6XnTpk0L+r3xxhs5O6byqrhjJZd/H/moX79+wfa+++7r8bbbbhu0aal3nWp/xBFHlOh36z7i0uHqyy+/9DgucY30tDx4TNPl4pT/VNq1a1fs3z1+/HiPeZYtWrpUUX1unDdvXi4OBxtIU5rM1k7FVr/++qvHHTt29Lhr165Bvx122KHIn//pp5+C7RYtWhQZm4XPubVr1055TGrRokXBdmmlkTMTBwAAAAAAIAF4iQMAAAAAAJAApFOZ2R577BFsx6ug/0lXSjczmzp1ataOKd89++yzHlevXj1lvyFDhnhc3qrS5JMuXbp4XK1ataBt9OjRHmvVB2ROXFlP6VTVbNMUgfiY0h1j7969PT7llFMyflxlSVwxZbvttvP4iSeeyPXhuCZNmhT579wHcy9d2kYmKiPhDxMnTgy2W7du7fEuu+wStB100EEea9WVJUuWBP0GDRpUrN+t1U4mT56cst+7777rMc9I6ye+nmrqm6YsxikbWmHz6KOP9jiuZqNjMW47++yzPdZz/dlnnxXr2MuDOHVG6Xi77rrrgrbhw4d7TEW+suP1118PtjX1Wr8jmJnVr1/f4zvvvNPjdKmlmp4Vp26lkyqF6vfffw+2n3vuOY8vuuiioG3BggXF/n2ZxEwcAAAAAACABOAlDgAAAAAAQALwEgcAAAAAACABWBPHzA455JBgu2LFih6PGTPG4/feey9nx5SPNN941113TdnvzTff9DjOdUUy7bzzzh7HOa3PPPNMrg+nXDjvvPM8jnN7S8vhhx/ucZs2bYI2Pcb4eHVNnHy3cuXKYFtz+nVNDrNwfally5Zl9Dhq1aoVbKdan+Cdd97J6O9F0fbcc0+PTzrppJT9VqxY4TGldzNr+fLlHut6DvH2lVdeucG/q3Hjxh7rWmJm4TXh8ssv3+DfVV699tprwbaOHV33Jl6nJtW6HPH+evTo4fGLL74YtG2//fYe6/oaet8u72rWrOlx/Eyga8f961//Ctp69erl8b333uuxlnU3C9ddmTlzpseffvppymPacccdg239Xsj1Nr247LeuJ7XVVlsFbbo2ra5b++233wb95s6d67H+Teh3DjOzDh06rPfxDhw4MNi++uqrPdb1rkoTM3EAAAAAAAASgJc4AAAAAAAACVBu06k222wzj7VUnZnZL7/84rGm86xZsyb7B5ZH4tLhOhVNU9ZiOlV41apVmT8w5ESdOnU87ty5s8eff/550E/L9iFzNHUpl3QKtJlZy5YtPdZrQDpxWd7ydO2Npxxr2eBjjz02aBs5cqTHffv2Xe/f1apVq2BbUzgaNmwYtKVKISgrqXr5Tu+nG22U+v+/vfrqq7k4HGSZpojEY0/TteJrJYovTkE97rjjPNY076pVq6bcx1133eVxnEa3evVqj4cNGxa0abrIgQce6HGTJk2CfuW5bPztt9/u8aWXXlrsn9Pr4wUXXFBknCk6/nQpiBNOOCHjvyufxelJOj5K4tFHHw2206VTaQq7/p098sgjQT8tYV5WMBMHAAAAAAAgAXiJAwAAAAAAkAC8xAEAAAAAAEiAcrsmzhVXXOFxXOp29OjRHr/77rs5O6Z8c9lllwXb7du3L7Lf888/H2xTVjw/nHbaaR5rueKXXnqpFI4GuXLNNdcE21pmNZ3Zs2d7fOqppwZtWkayvNHrYVxq+NBDD/X4iSeeWO99L126NNjWtTdq1KhRrH3EeePIjlQl3uO1BO67775cHA4yrFu3bsH23//+d491zQaztcvsIjO0RLiOt5NOOinop2NO1y7SNXBi119/fbDdokULj4844ogi92e29r2wPNF1UYYOHRq0Pf744x5vvHH4VbZevXoep1s/LBN0DUD9m9Ey52ZmN9xwQ1aPA2Y9e/b0eH3WJDrvvPM8LslzVGliJg4AAAAAAEAC8BIHAAAAAAAgAcpNOpVOOzczu/baaz3+/vvvg7Y+ffrk5JjyXXFLAl544YXBNmXF80ODBg2K/Pfly5fn+EiQbaNGjfK4efPmJdrHZ5995vE777yzwceUL6ZPn+6xlsA1M9tll108btq06XrvW8voxgYNGhRsd+/evch+cUl0ZEbdunWD7Til40/z5s0LtidMmJC1Y0L2HHzwwSnbXnzxxWD7o48+yvbhlHuaWqVxScXXSU0P0nSqfffdN+hXrVo1j+OS6PlOSzrH17VmzZql/Ln999/f44oVK3rcu3fvoF+qJR5KStOd27Ztm9F9o2hnnXWWx5rCFqfYqU8//TTYHjZsWOYPLEeYiQMAAAAAAJAAvMQBAAAAAABIgLxOp6pevbrHd955Z9BWoUIFjzUVwMxs/Pjx2T0wBHS6qJnZmjVr1nsfK1asSLkPnU5ZtWrVlPvYaqutgu3ipoPplM8rr7wyaPvxxx+LtY98dNhhhxX57y+88EKOj6R80qm96So0pJvGP3DgQI+33XbblP10/7///ntxDzFw+OGHl+jnyrNJkyYVGWfCl19+Wax+rVq1CranTp2a0eMor3bfffdgO9UYjqs7Ipni6/APP/zg8X//+99cHw6y7KmnnvJY06mOP/74oJ8uN8BSD8UzZsyYIv9d04/NwnSqX3/91eOHH3446Hf//fd7fMkllwRtqdJckR0dOnQItvXaWKVKlZQ/p8t0aDUqM7Off/45Q0eXe8zEAQAAAAAASABe4gAAAAAAACQAL3EAAAAAAAASIO/WxNG1bkaPHu1xo0aNgn6zZs3yWMuNI/emTJmywft4+umng+0FCxZ4XLt2bY/jfONMW7hwYbB94403ZvX3lSV77rlnsF2nTp1SOhKYmQ0YMMDjW2+9NWU/LV+bbj2b4q51U9x+9957b7H6oXTomkpFbf+JNXCyQ9f0iy1dutTjfv365eJwkAW6NoM+p5iZLV682GNKiucfvU/q/fnII48M+l133XUeP/nkk0HbjBkzsnR0+emVV14JtvX5XEtSn3322UG/pk2berzPPvsU63fNmzevBEeIdYnXTtxiiy2K7KdripmF606NGzcu8wdWSpiJAwAAAAAAkAC8xAEAAAAAAEiAvEunatKkicdt27ZN2U/LR2tqFTInLt0eTxPNpG7dupXo57SsYLo0kBEjRng8YcKElP3Gjh1bouPIB0cffXSwramNH3/8scdvv/12zo6pPBs2bJjHV1xxRdBWs2bNrP3eJUuWBNvTpk3z+JxzzvFYUx5R9hQWFqbdRnYdeOCBKdvmzp3r8YoVK3JxOMgCTaeKx9fIkSNT/pymEGy99dYe698FkmPSpEke/+tf/wrabrvtNo9vuummoO2UU07x+KeffsrS0eUPfRYxC8u8H3fccSl/bt99903Z9ttvv3msY/aqq64qySGiCHq969mzZ7F+5rHHHgu233zzzUweUpnBTBwAAAAAAIAE4CUOAAAAAABAAvASBwAAAAAAIAESvyZOgwYNgu24hNyf4jUhtKwusuOYY44JtjWXsWLFisXax4477ujx+pQHf+ihhzyePXt2yn7PPvusx9OnTy/2/vGHypUre3zIIYek7PfMM894rDnEyJ45c+Z4fMIJJwRtRx11lMcXX3xxRn+vlu00M+vfv39G94/c2HTTTVO2sf5Cduh9Udf3i61evdrjNWvWZPWYUDr0Ptm9e/eg7Z///KfHn376qcennnpq9g8MWfXoo48G2+eee67H8TN1nz59PJ4yZUp2DywPxPetSy65xOMqVap43K5du6BfrVq1PI6/TwwePNjj3r17Z+AoYRaej88++8zjdN8ddQzouc1nzMQBAAAAAABIAF7iAAAAAAAAJEDi06m0ZK2ZWf369Yvs99ZbbwXblEvNvVtvvXWDfv6kk07K0JEgU3Qq//Lly4M2Lcver1+/nB0T1haXdddtTUGNr6eHH364x3o+Bw4cGPQrKCjwWKe+IrlOP/30YPu7777z+Prrr8/14ZQLv//+u8cTJkwI2lq1auXxzJkzc3ZMKB1nnXWWx2eeeWbQ9uCDD3rMWMwvS5YsCba7dOnicZzKc+WVV3ocp9xh3RYtWuSxPuto6XYzs06dOnn873//O2hbvHhxlo6ufNtvv/08rlu3rsfpvrtrmqmmHOczZuIAAAAAAAAkAC9xAAAAAAAAEqBgfdKKCgoKykQO0p577unxqFGjgjZd0Vp16NAh2I6nKpd1hYWFBevutW5l5RyWUxMLCwvbrbvbunEeSw9jMS8wFtfhhRdeCLb79u3r8RtvvJHrwylSPo/FbbfdNti+4YYbPJ44caLHeVD9rdyORX2W1UpDZmHK64ABA4I2TV3+5ZdfsnR06yefx2JZEVff3W233Tzu2LGjxxuQ0lxux2I+yYexOHnyZI932mmnlP1uu+02jzW9MA8UaywyEwcAAAAAACABeIkDAAAAAACQALzEAQAAAAAASIBElhjv3Lmzx6nWwDEzmzVrlserVq3K6jEBAJAvtOQqcu+bb74Jts8444xSOhJkyzvvvOOxltQFitK1a9dgW9cNadq0qccbsCYOUCZUq1bN44KCv5b4iUu6/+9//8vZMZVFzMQBAAAAAABIAF7iAAAAAAAAJEAi06nS0emF+++/v8fLli0rjcMBAAAAgBL7/vvvg+1GjRqV0pEA2dW3b98i4+uvvz7ot2DBgpwdU1nETBwAAAAAAIAE4CUOAAAAAABAAvASBwAAAAAAIAEKCgsLi9+5oKD4nZFRhYWFBevutW6cw1I1sbCwsF0mdsR5LD2MxbzAWMwDjMW8wFjMA4zFvMBYzAOMxbxQrLHITBwAAAAAAIAE4CUOAAAAAABAAqxvifGlZjYnGweCtBpkcF+cw9LDeUw+zmF+4DwmH+cwP3Aek49zmB84j8nHOcwPxTqP67UmDgAAAAAAAEoH6VQAAAAAAAAJwEscAAAAAACABOAlDgAAAAAAQALwEgcAAAAAACABeIkDAAAAAACQALzEAQAAAAAASABe4gAAAAAAACQAL3EAAAAAAAASgJc4AAAAAAAACcBLHAAAAAAAgATgJQ4AAAAAAEAC8BIHAAAAAAAgAXiJAwAAAAAAkAC8xAEAAAAAAEgAXuIAAAAAAAAkAC9xAAAAAAAAEoCXOAAAAAAAAAnASxwAAAAAAIAE4CUOAAAAAABAAvASBwAAAAAAIAF4iQMAAAAAAJAAvMQBAAAAAABIgI3Xp3NBQUFhtg4E6RUWFhZkYj+cw1K1tLCwsGYmdsR5LD2MxbzAWMwDjMW8wFjMA4zFvMBYzAOMxbxQrLHITBwgd+aU9gEAMDPGIlBWMBaBsoGxCJQNxRqLvMQBAAAAAABIAF7iAAAAAAAAJAAvcQAAAAAAABKAlzgAAAAAAAAJsF7VqYBsKCgo2ULqFSpU8LhixYpB25o1azz+9ddfS3ZgKHWVKlXyeOON/7pc/fzzz0E/zjEAAACA8oCZOAAAAAAAAAnASxwAAAAAAIAEIJ0KObPRRn+9M9xss8083mabbYJ+NWrU8LhKlSoet2zZMujXoEEDj99///2gbfjw4R6TapMc+jdiFp7/3377zeMff/wxZ8eEtcUpkIWFhaV0JAAAAED5wkwcAAAAAACABOAlDgAAAAAAQALwEgcAAAAAACABWBMHGaVlvzfddNOgrXv37h6fdtppHjds2DDop+ttbLLJJh5vueWWQT8tOb148eKg7c033/R4yZIlHrN2R9mjfzPNmzcP2vr27evxv/71L48nTJgQ9OO8ZkfFihU9HjhwoMedOnUK+n344Yce9+zZM2hbuHBhlo4OqcRrFqXCuMlv8d+B3k91jTHWjdtwqcYcYwxINh3b+rxqZlapUiWPK1eu7HG1atWCfroOaHxNWLFihccrV670OF77cfXq1Sn3gfKJmTgAAAAAAAAJwEscAAAAAACABCCdChsknlpYq1Ytj88444ygrUePHh7rtEOdImhmNmfOHI81Tapp06ZBv7p163qsUxCRLDrF/9xzzw3a2rdv7/GyZcs8/v3337N/YOVQPJ4vvfRSj0855RSP41LwOhY1tcrMrH///h5z3jJLx46mpW6zzTZBv++++87jRYsWefzDDz8E/dJN19Zzrr83/lvQfWrKDnJDp/6feuqpQZveg6+//nqPR4wYkf0DywP62e64445BW+fOnT3+6KOPPJ48eXLQ75dffvFYx1gm0iPi67emw+qYNTNbs2aNx6RppKep+2bhfYx7Wn7Q+9hWW20VtOl18+9//3vQ1qBBgyL3Ed8X9doRjzFNZ9VY79VmZueff77Hb731VtD2008/GcofZuIAAAAAAAAkAC9xAAAAAAAAEiDn6VTpVvnW7Xgqmk5Z1OlmTNcuXfG0QF2BPa46pWlSOpU3ToVaunSpx5pCE08H1qnCWo3KjL+Lsiyu4qHTUQ877LCgTSuLLViwILsHVk7p+dD0NTOzXr16FdlPx69ZOBavuuqqoO29997zWFML4n1g3eL7Yv369T2Yu+ouAAAe20lEQVTu3bu3x5o+ZWb29ttve6zX2/gc6L01vrZrtY0DDzzQ4zZt2gT9Xn31VY9Hjx4dtHHOs0/Pk1b0MzPbdtttPd5tt908HjlyZNCP+2fR9F41bNiwoE2fT/QaOHv27KDf8uXLPU5XFay4aU16Tdh6662DtoMOOshjTZ8zM5s3b57HRxxxRJHHZ5Y+DSSfVa9e3eOzzz47aJs+fbrHb7zxhsfxsyypVmVLfP/cfPPNPdZnz5tvvjnoV69evZT7SFXlL/5+q+NIUyrjn9PrSDye9X4fV//9+eefzax8/83pZxyfp3Spbnpd0/OZhPsgM3EAAAAAAAASgJc4AAAAAAAACcBLHAAAAAAAgATI+Zo4msd31FFHBW3nnHOOx7Vr1w7atATilClTPJ44cWLQT/PxdT2VuIy1bsd5yZofp7lz8Voemi9XnnKFla6FYRZ+loMGDQraFi5c6LGWbKxTp07QT8vjai7qDjvsEPTTknpjxowJ2uLzjbIjzhXWfPwtt9wyaBs8eLDHf+b8YsOlKpX7wgsvBP00Z1zHdlyaulKlSh7H5/Dpp5/2WMfp1VdfHfRbvHhxsY69PIvz4M866yyPtSzq/fffH/SbOnWqx7puQ3zfSndP03V2vvjiC4+PPvrooN91113n8apVq4I2XT8CmRGvFad/E9ttt13Qps8zOobjZxv8IR5vDz/8sMeNGjUK2rTkr64FFV8r0607VRK6j7gU9gEHHOBx/Jyl65Pp81L8t1Ce1sTR+9jAgQM9jr+r6LpBQ4cO9bhfv35Bvy+//NLjdOsfIbNSrROl10Yzs5NOOsnj7bff3uN43Ot9MS77/e677xbZFu/jm2++8XjGjBlB2/fff+/xihUrPNbvTPE+9GfKk/j6pOuw6ndEXb/MzKxJkyYed+jQIWhr0aKFx5988onHN910U9Bv2rRpHpeV9XKYiQMAAAAAAJAAvMQBAAAAAABIgJynU1WpUsXjeBr2zjvv7HG66WxauvqYY44J+l122WUea6nquLSplivWfvHvatWqlcfxVNVXXnnF4/vuuy/l/vN5CmpcKk/LVs6fPz9o0ymOen7jknjaVrduXY+rVq0a9NN0Kp3eb0Yp27IsTqfSUrdxasCkSZM8LivTF/OBThvXKcZxKpSOTU2n+fbbb4N+Ombj66TuU0tT69Rgs3DqKumQf9HPs3Xr1kFbp06dPNZUtTjN+Mcff/Q4XQnSdPcqvdbr/U2nM5uFZazj+zgyb4sttgi2NYUmHouakqplkstzWdp0tMy0WThFP06TuuWWWzzWlMVs37f0uUqfoc3M9txzT481TcPMrG/fvh7r2M7n59VYXGp433339fhvf/tbyn6pfqZatWpB2x133OHxhAkTgjbGXOZUrlw52N5rr708PuOMMzzWEt1m4fnS9CS9NpqZPfLIIx6PGjUqaNNlO/Q+G4/7TKdR5jtNm9LvBXEa67nnnuuxjsX4WVb3F98X9b2ELuWi3//NwhTLJ598MmjTv4Ncjm1m4gAAAAAAACQAL3EAAAAAAAASgJc4AAAAAAAACZDzNXE0bywu3/Xyyy97HOez6RoOmqcc5wBrvpyW14zLktWsWdPjuGScHqMeh67FY2bWsmXLIo/PzOyaa67xOJ/X8ohzO3U7/sw1r1hzWPVzNDNr1qxZkXGcnz5nzhyP41J85BuXXVq22izMO43/nrR8I3nEJRfn9GtZ8W7duqX8OV3bQculxiUydX2q+FqopR01B33//fcP+ukaY+PGjQvayvO513zwLl26BG26loWWh9e1T8zCzy/dZ1ncNs0pj3PU9do+a9aslPtDyem9VdeNMzPbZZddiuxnZjZz5kyPx44d6zH3y7/oZ9a5c+egTa9f8Zpen3/+ucfZvl7p9Vyfc88888ygn47T+++/P2j78MMPPU73jJrP1954bYzdd9/dY13DRJ81zcymTJnisa4JputpmJkdd9xxHs+dOzdo0+8d+fwZZ4t+H7jooouCtq5du3qsY2XYsGFBP70e6jNHPLb1+Sa+VnLuSi7VujdmZs2bN/e4d+/eHu+6665BP33e0LVQdQ1Hs/D5ddWqVSn3Ua9ePY/j75yXXnqpxyeeeGLQ1rNnT49z+b2FmTgAAAAAAAAJwEscAAAAAACABMh5OpVO29TywWZmkydPLtY+0pUKq1Gjhsc6zbtixYpBPy0nF0+P22qrrTzeb7/9PNZSvGZhac+tt946aNMyyvmcTrU+dLqcplDFU4D1fOi5jsuZ63RULe0X/5zGTH0sHXoOGjduHLTVqVPH4zgNZOnSpdk9sDymn7mmj5qZ3XXXXR7rFHCdQm5m9vXXX3us6a4fffRR0C/dWNSS04ceeqjHO+20U9Dv+OOP93jatGlBW1zSPJ/FKTBVq1YtMjYLpwjPnz/f43TXuZJeD/XnWrRo4XFcVlePI05zRWbo88U+++wTtGm6avzsoWXoly9fnp2DSzj9bONrlI6XuAyxPt/EY7g44p/R7ThFVe+hWmJXS4qbhddNLZNsFqaIlFfx9wK9V+m97/nnnw/6vffeex7rs7+WJTcza9u2rceHH3540PbYY495HN8z8QcdA3GqmqYHtmvXLmjTtJq7777b4/79+wf9Vq9e7bF+7+B7QnbEaf2ainjwwQcHbX369PFYU5ziZ1RNiXvzzTc9jlO59X4Xf5fU7/wdO3b0WFO6zMLUVU1bNjO79dZbPdYS99n+/s9MHAAAAAAAgATgJQ4AAAAAAEAC5DydKp3iTmHTfvG0KF1VfMGCBSU6Dp0WqylT5513XtBPp/wPGjQoaCOFau1UN62I06tXL4+1OpGZ2dSpUz3WdJq4itinn37qcUmrsSA3dBrlgQceGLTplMp4ivoPP/yQ3QPLYzpV/JJLLgna2rRpU+TPxBU09Lo2cuRIj+M0N70O61Rms7Cyh45FTaMzM+vQoYPHt9xyS9DWo0cPj+Oxnm/itAq9PjZt2jRo02tlqjTUeLu4lYjifei9UP+e4ut8v379PI6rQCAzdGzHVd60LU7TeOaZZzyOxyn+oOlUcQqHVi7V5w+zMOUpHhOpaL84JV+n+Ldv3z5oO+mkkzzW6f+xxx9/3OP42l5e6XUt/sw1NXT27Nkef/LJJ0E/bdN7YXxf1TSfuJrNvHnzPH799dc9zvf72/rQ9OEBAwYEbZq6FqdbX3jhhR6/9NJLHsepOHw3yD4db1WqVAnaNMXwP//5T9CmSwDofUyrKpqZPfzwwx7r94f43G666aYe67XVLKxOpT8Xp7FqqnJ8jdf7bknSaUuKmTgAAAAAAAAJwEscAAAAAACABOAlDgAAAAAAQAKUqTVxMq2k+Y66fsdxxx3nsebUmZkNGTLE448//jhoY02ccK0TM7POnTt7rGs7aJk/M7MZM2Z4vGTJEo/jz18/8zi/n3KBZYv+LZx++ukp+z300EPBdpzDjOKrUaOGx/E6RJq/q6VmtUyiWVhadeXKlR6nG1PxmiuaH7xixQqPde0xM7NatWp5HJfK1bUL8r1sdZxrvd9++3ncoEGDoG3ChAke6/UxHjd6fdQ4Ple6rWuDmIXrO2jpzfh8PP300yn3j8zYcsstPY7LYOt40zVczNKvGYA/6LNbvOairvGk5ajNzI444giPda0qfYYxC8dfw4YNPY6vebr/nXfeOWirX7++x/q8OmrUqKDfAw88UOTvLc90fOjnb2bWqFEjjxcvXuxxvDafXl/1c9V7pFl4n9Wy8GZmO+ywg8fjxo3zuLyviaPn55RTTvH4kEMOCfrp9Wv48OFB29tvv+2xniuuebmn5zMuI67r5+n6R2bh90Jddypei0zXp9K1c+LnS13fJl7rTMeiXmtbtmwZ9NNnrHi9uUcffdTjXH7/ZyYOAAAAAABAAvASBwAAAAAAIAHyOp2qpHRKpU5l1/LlZmH5xvI+BfJPOnVOyzWame2+++4ea6k5nQ5nFk6d01SPeIqapmbEJd2YNlm2NGvWzOM4JeS7777zeOjQoUEb57H44jGg07fj6aM6xVjLmw4bNizo9/3333usqTE6hd8s/XnSNp0iG09R1+mv8VRYLd06evToYv3epNJyl2ZmBxxwgMdxqpVO+dfpwvHnoqlReh2N71v6c3EZztNOO81jTRPQ+6BZeF1G5uj4btGihcfbbLNNyn5ffvll0EbJ93XTa2OfPn2CNk2v1xLHZmG6uKYPL1iwIOin50THZTzedCzGaYn6XKTp53E6rN5b8Qe9d7Vt2zZo02cTvdZq+qKZWfXq1YvsF6dY6PVZU+DM1j7f+IOeH73nxOm9r732msd9+/YN2vQ5I125Zx1j6fqlayNlOD397I4//vigTcdAnAKuaahz5871WFOCzcKUV/1d8TNknTp1PI7TU/X5sm7duh7Hz2L6d/Xiiy8GbU888YTHuXwuZSYOAAAAAABAAvASBwAAAAAAIAFIpzKzLbbYIti+9957PdaqKL169Qr6aeUHptT9QadCanUcM7PtttvOY51uplPlzMxmzZrlsU4bTjfdLk61ysc0i6TR6a89e/b0OE7Fue222zxevnx59g8sT8V/81oBTtNfzMKUl3vuucfjuLpGqlX21+d6p/vQMRxPd9XtuJJKXLkgn8VTePU6GqdHaFqqTheOx1jNmjU91s85niauaQNascHMbLfddvNYpzCPGDEi6Me9MDv0vF122WUeaxqdWTh24jSDuNoS0osrrw0YMMDjMWPGBG3nnXeex/vss4/HcZVOrTqlzzdxuohWQon3oWmumkIVV0mlItXa9Po0b968oE3vVbocwF577RX00yUXNIUqTpFatGiRx/F1Xfev3zP03JZH+qxSr169lP30+1dcoU/Hjp6DOJ00VTVGPR9m4XeXeB/6N5QuXVWfz8rT9xP9jK+99tqgTdO59VkmNn/+fI/je5iOI31+0bQoM7O9997bY70+m4UpyXo/jdPN+/fv7/Htt98etH377bcpjz+bmIkDAAAAAACQALzEAQAAAAAASABe4gAAAAAAACRAuV0TR/PebrnllqCtQ4cOHn/00UceP/XUU0E/cv/XpmssxDmJmmequdqas2oWrtehn7GWdzML88nLU45pUugY05J+WnbTzOzBBx/0mPOYOZrHHZc+1RzjmTNnepzumlbSc6P71H00bNgw6Kdrk8X5xZ999lmJfncSxXnYen2M14zS8rZ6vdU1cMzCtRo0b1/XDjAL1+to3rx5yt+l6wDE60ogO2rVquXxHnvskbLflClTPH799deDNq6vG0afWz799NOgTdcpatasmcfxudJx+s0333gcr82oa1DpuDQze/PNNz1+++23PWbNo3XT+9HYsWODNi1b3b59e49r166dch+6Nku8hpyuMff1118HbXo9bdmypcd6bzZbey3IfKdr0+iaVPEaeptvvrnHeq7MUo8xPVdm4XnU6+vBBx8c9NOxGK9L98gjj3j88ssvexw/c+m9uzytVaX3nPiaecopp3gcr4mja/LpmjXxOdRnGP3+GT8DtWjRwmNdL9Is/K6i19CBAwcG/e64446Ux1FamIkDAAAAAACQALzEAQAAAAAASIC8TqfSqVU6ddHMbM899/T4xBNPDNp0qttFF13kcTw9DmvT8oBxiVotk6kpU1988UXQb8GCBUXuO0710GmmTBMvfXG5Yp3OqCWi45Ly5b2kZqbEn79ON45LTuuUZZ3GH++juHT8xfvQ3924cWOPGzRoEPTTa0d8DdC/mXwf6/F1TtOrtNy4mVmrVq081ung8T703qXTgON++tlqOl68jzlz5hT578iceMy2a9fOY72exuOhd+/eHnNucken4Wv6Z3y/02ugPmtqSo2Z2UEHHeRxXH58+PDhHuuzVL5fGzMtTom47rrrPL7zzjs9rl69etBP01M1/Wnp0qVBP723xik0+p1En5XjFK90ZavzkX5OTz/9tMdnnnlm0E9LS3fs2DFo0+uefk+IvwfqtqbsxEtBaOnq+PlG08I1DWv06NFBvyeffNLjOCWrvNJzE38mupSJPtto6pNZ+EykKVlxeqpeX+M08lR/c7169Qr6aXpkWbnWMhMHAAAAAAAgAXiJAwAAAAAAkAC8xAEAAAAAAEiAvF4TR3PKNafOLMx3jUubjRw50mMtiVZWcuDKMs011LJ8ZuHnrKUD47xkzZPU/cUlxjU3NV4/QM8V5y030uUK63nUktZma5flRGbUq1fPY11DwyzMAdbyqdOnTw/6pSs5rnT8xXnnugaErtehOe1m4TgdPHhw0Ka5yPnuhx9+CLY1l75Tp05B26RJkzzWEqZxKXL9bPV6G6+ZoqXd47LGO+20k8dxvjkyLy6p261bN4/1WqtropiZffDBBx5z7ysdet2Mx7OWmtZ1AuNnGF3rIX5G0vUiylsJ6kyKP7tZs2Z5rPeq+vXrB/0aNWrksa6FpOvQmZk1adLE47jksY5vfT6qU6dOymMqD+NZn020xHP82epzS+vWrYM2/az1eSR+RtXxl6pUtVm4Ll38fKPr5eyxxx5FHoOZ2XPPPWcoPv07WLx4sce6dqJZeG523XVXj7V8uVn4DkB/xsxsyJAhHl966aUex8+dZXH8MRMHAAAAAAAgAXiJAwAAAAAAkAB5l06l0+A0fUenRpqZNWvWzOO4hN8111zj8U8//ZThI8xvOmVNp9+bmVWuXLnIn0lXelGn7cfTjXVaXUlLI+s+dWqlWZiCosek0yfNwil3Ou3PLEwBK4tT8TIpLv231157eaznavz48UG/fP9cciUeA1oWNT43WiJVSy9OnDgx6Kd/25oiEJe81Wvt3nvvHbTptbdFixYpj1fLVj/wwANBW3lKudPp+WZmDz74oMePPvpo0KbXF/084ynfOhVdp43HKTuawhFPW9ZrsV7n49+FktNz2LRp06BNp+rrNfOdd94J+n3//fdZOjqURJySqtcyTZ2JU0L0mr1o0aKgLb5GIDP03Lz//vsef/jhh0G/+Fn0T/HSDM2bN/d45513DtqOP/54j/V+HJfL1lS6uAxzcdOdk0SvbUuWLPG4f//+QT99Dm/btm3Qpmk1mtKmsVl4L9Rzmi7NOF3ao94z437xchBIT/8OdFzGzyX6+V9yySUe67NmvL9nn302aLv44os9jtNfyzpm4gAAAAAAACQAL3EAAAAAAAASIO/mQet0ZF1B/phjjgn66TTEfv36BW2ff/55lo4u/+m0t7iCiU7d15Xl41XcdTqbTjONpxBrVY54CrlOh0yXBtKgQQOPDz744KBNp2Tq76pbt27Q77XXXvN4+PDhQZumV+VjSoiON506bGZ27LHHFvkz8dRk0qkyI/4cdQp+nLqkY/Fvf/ubx1o5xcxswYIFRe5/9913D/p16dLFY037MAtTefQ45s2bl3IfSZvSmk06Dbu4U7Lja6WmBes0b51ObhamlMbXb93Wa1mckoWS03Oj49IsHEf6d/D6668H/fLxPpNk8XVZn0fatGnjcXzd1HEVp83E1VWQeanSOYra/lNcFVBTsrRqnJnZqFGjPG7Xrp3HcUrWAQcc4PHcuXODNn2WipclyAf6dx8/m+izxLRp04K2xx9/3GNNu9pvv/2Cfv/4xz881uUT4qplqb6TmIXfZfR44++RLM1Rcnpf3HrrrYM2/Z6h1TvjdLZx48Z5fP755wdtSX7eZCYOAAAAAABAAvASBwAAAAAAIAF4iQMAAAAAAJAAiV8TJ17rQXP8L7jgAo+rVasW9NNSurfddlvQFudDovi0FJ+WRjQLz4GWz4zXmNFzqP203LFZuO6NrhdgFuamapuWUzYL1x3YbrvtgjYtnav/LXF+uq6zE7fl+3ov+t8er4Gja1KtWrXK4zi3Od8/o1yJP8cXX3zR43hNMC3TqOsy/N///V/Qr3Llyh5rrn6cF679UpVfNQtLpMalyL/66quUP4cNk2p9hzhPX9dAikuH63o5uiZLPq7FUFp07MTrN+jnr+ftvffeC/rx/FK26Xo2Wka+cePGQT99to3XwmJNnGTQ6258f9bnIH1u7N69e9BP15+bP39+0PbFF194vHTp0pS/Kx+l+2z189R1it5+++2g38knn+zxNtts43H8DFOrVi2PdY0ds3DtKv2e8NZbbwX9uE+WnD6v7r///kHbmWee6XGqe6RZWEY8XkM1yZiJAwAAAAAAkAC8xAEAAAAAAEiAxKdTxdPeWrVq5fGRRx6Z8uduueUWj5NcXqys0Wlqffv2DdpuvfVWj7VcbbrzpOlU6co8xqVyNfVD2+IS4zplOZ7umKqE+fjx44N+Om1SU7zi/ecj/TzjacA67VTTNDS1Ctnz0ksveTxkyJCg7fTTT/e4Zs2aHuu0YbP0qVGpxOkcU6ZM8fjQQw/1eOHCheu9b2RWnP6p90KdmmwWjnW9rpHakTn6ubZo0SJo03uhXkPnzZsX9CsPqRRJpmNOU2Di0tL6txA/V/zyyy9ZOjqUBv07iMuUt27dusjYzGz06NEe6/2elMq/6PUwXuJh6NChHuv3kxo1agT9NGUqfibS+5+ma7366qspjwPrps8bzZo187hnz55Bv+rVq3us3+FuvPHGoN+kSZMyfYhlAjNxAAAAAAAAEoCXOAAAAAAAAAnASxwAAAAAAIAESOSaOJqTGOeN33DDDR5vvfXWHs+dOzfoN2LEiCwdXfmm69Q88sgjQZvmgmuZuEWLFgX9tLStlgePy4hrmeM4nzxVW7zuzZdffunxCy+8ELSNHTu2yH7p1lCK817zPQ9WS0vXr18/aNPPWtdkYU2c3NB1FC677LKgbcmSJR5riUZdH8csHIt63Y3H0YwZMzy+5557gja9DsRlH1G26DU63XpIK1eu9Jg1cTJH10GpVq1ayn66hka8zgPKNn1GeuONNzzu06dP0E+vvfH1Nt/X2itv9Boafzc56qijPN5zzz2DtvPPP9/jDz74wOPFixcH/fL9ObS44nU19Zm/cePGHp999tlBP/0+EY9FHcMXXXSRx/H3GqwfXZNPn1Hj7xn6zPLhhx96fMcdd6Tsl0+YiQMAAAAAAJAAvMQBAAAAAABIgESmU1WsWNHjHj16BG3bb7+9x99++63HxxxzTNCPKeDZF3/GDzzwgMcPPfSQx/E0t1RThePp/emmFKeaPhr/u/5uppyuP01x06mMZmHJy/79+3scT2lF9q1evTrY1vKLd999t8fbbrtt0K9BgwYea3nTt956K+g3YcIEj+Nxz7hKpnHjxgXb7du39/i+++7zOF+nKZcGvaeNGTMmaKtatarHOlWcFMVk0euhXpfj5xlNp9JUD7P0qY5Itjg9UtOTO3ToELS1adPG43bt2nkcl7emJP0f4mcRTe3/z3/+4/Gdd94Z9NPvnBqbhcsrsFRA5mjp8JNPPtljTbMyC1OLL7jgAo91OYF8xp0AAAAAAAAgAXiJAwAAAAAAkACJTKeqXbu2x127dg3adLqcrho+ffr07B8Y0tJzky6lJlX6BdP2y56FCxd63KVLl6BNp/lz7soWrbCg01E1NjObMmWKx3H1NuQfnXY/YMCAoO2jjz7yeOLEiR6TLpc5ml7TvXv3oE0/519//bXIf0fZp+dLq6bGKTA77LCDx+PHjw/auJ/mr/jZePLkyUXGZmGanS4lEafC6v2e60XR9HPX6ovIjQoVKgTb3bp181irg8XjQ6+bX3zxRZaOruxiJg4AAAAAAEAC8BIHAAAAAAAgAXiJAwAAAAAAkACJWRNnk0028fjwww/3OC6d9/7773s8cuRIjylrDGSers2gMYBki9cF0JLXrKuQfZQFzn9akvjKK68M2nTtx0mTJgVt/G3kr3i9o+XLl3s8ZMiQoK1jx44ejx071uO41DXXa5RFBQUFHtesWTNo69y5s8f63eKrr74K+t1+++0el8frIjNxAAAAAAAAEoCXOAAAAAAAAAmQmHSqSpUqeazTDZ9//vmg36BBgzxesGCBx6RTAQBQMkzJBzJLn2U/++yzoG3atGkeM/bKrx9++MHjESNGBG1aen7evHke830HSZDuujZr1iyPR48e7fG1114b9Cvv10lm4gAAAAAAACQAL3EAAAAAAAASgJc4AAAAAAAACVCwPjlkBQUFpZZwVqFCBY+rVq3qsZYeNzP7/vvvPdZ84zVr1gT9kpYzWlhYWLDuXutWmucQNrGwsLBdJnbEeSw9jMW8wFjMA4zFvMBYzAOMxezbaKONUm5rueb4+01ctjwNxmIeSOJYjP+2N998c4/1PcXPP/8c9NPy43m2Jk6xxiIzcQAAAAAAABKAlzgAAAAAAAAJsL4lxpea2ZxsHMi66PTAZcuWlcYhlKYGGdxXqZ1DcB7zAOcwP3Aek49zmB84j8nHOcyBOC1qPdKkiovzmHyJPIfx3/LKlStz8WvLsmKdx/VaEwcAAAAAAAClg3QqAAAAAACABOAlDgAAAAAAQALwEgcAAAAAACABeIkDAAAAAACQALzEAQAAAAAASABe4gAAAAAAACQAL3EAAAAAAAASgJc4AAAAAAAACcBLHAAAAAAAgAT4f91LIvocU3AzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efe6c051320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    ax = plt.subplot(2, n, i + n + 1)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = encoder.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 64 and 74 for 'model_10/dense_28/MatMul' (op: 'MatMul') with input shapes: [?,64], [74,256].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/ganimedes/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    653\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    655\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ganimedes/anaconda3/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ganimedes/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 64 and 74 for 'model_10/dense_28/MatMul' (op: 'MatMul') with input shapes: [?,64], [74,256].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-26937a46bb94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_double\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mdiscriminator_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mdouble_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_double\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ganimedes/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ganimedes/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m   2056\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_tensor_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2058\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2059\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ganimedes/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mrun_internal_graph\u001b[0;34m(self, inputs, masks)\u001b[0m\n\u001b[1;32m   2207\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0;34m'mask'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m                                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputed_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2209\u001b[0;31m                             \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2210\u001b[0m                             output_masks = _to_list(layer.compute_mask(computed_tensor,\n\u001b[1;32m   2211\u001b[0m                                                                        computed_mask))\n",
      "\u001b[0;32m/home/ganimedes/anaconda3/lib/python3.6/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ganimedes/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ganimedes/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m       return gen_math_ops._mat_mul(\n\u001b[0;32m-> 1844\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   1845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ganimedes/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_mat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   1287\u001b[0m   \"\"\"\n\u001b[1;32m   1288\u001b[0m   result = _op_def_lib.apply_op(\"MatMul\", a=a, b=b, transpose_a=transpose_a,\n\u001b[0;32m-> 1289\u001b[0;31m                                 transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   1290\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ganimedes/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ganimedes/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2630\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2631\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2632\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2633\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ganimedes/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1909\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/home/ganimedes/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ganimedes/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    593\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    594\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ganimedes/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    657\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 64 and 74 for 'model_10/dense_28/MatMul' (op: 'MatMul') with input shapes: [?,64], [74,256]."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "discriminator_input_dim = (74,)\n",
    "generator_input_dim = (110,)\n",
    "batch_size = 128\n",
    "epochs = 50000\n",
    "\n",
    "discriminator_input = Input(shape=discriminator_input_dim)\n",
    "generator_input = Input(shape=generator_input_dim)\n",
    "input_double = Input(shape=generator_input_dim)\n",
    "\n",
    "def custom_activation(x):\n",
    "    return (K.sigmoid(x) * 3) \n",
    "\n",
    "def discriminator(x):\n",
    "    hidden1 = Dense(256, activation=\"relu\")(x)\n",
    "    hidden2 = Dense(256, activation=\"relu\")(hidden1)\n",
    "    return Dense(1, activation=\"sigmoid\")(hidden2)\n",
    "    \n",
    "def generator(x):\n",
    "    hidden1 = Dense(256, activation=\"relu\")(x)\n",
    "    hidden2 = Dense(256, activation=\"relu\")(hidden1)\n",
    "    return Dense(64, activation=custom_activation)(hidden2)\n",
    "\n",
    "def random_input_batch_with_class(labels):\n",
    "    result = []\n",
    "    for a in labels:\n",
    "        noise = np.random.normal(0, 1, (100))\n",
    "        cond = np.zeros(10)\n",
    "        cond[a] = 1\n",
    "        result.append(numpy.concatenate([noise, cond]))\n",
    "    return np.array(result)\n",
    "\n",
    "generator_model = Model(generator_input, generator(generator_input))\n",
    "discriminator_model = Model(discriminator_input, discriminator(discriminator_input))\n",
    "discriminator_model.compile(loss='binary_crossentropy', optimizer=\"adadelta\", metrics=['accuracy'])\n",
    "generator_model.compile(loss='binary_crossentropy', optimizer=\"adadelta\")\n",
    "\n",
    "img = generator_model(input_double)\n",
    "discriminator_model.trainable = False\n",
    "valid = discriminator_model(img)\n",
    "\n",
    "double_model = Model(input_double, valid)\n",
    "double_model.compile(loss='binary_crossentropy', optimizer=\"adadelta\")\n",
    "\n",
    "X_train = data_x.reshape(60000, 64)\n",
    "half_batch = int(batch_size / 2)\n",
    "for epoch in range(epochs):  \n",
    "    if epoch % 1000 == 1:\n",
    "        n = 10\n",
    "        plt.figure(figsize=(20, 4))\n",
    "        for i in range(n):\n",
    "            ax = plt.subplot(2, n, i + 1)\n",
    "            plt.imshow(decoder.predict(generator_model.predict(random_input_batch_with_class([0])).reshape((1,4,4,4))).reshape(28, 28))\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            plt.gray()\n",
    "        plt.show()\n",
    "    idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "    labels = y_train[idx]\n",
    "    imgs = numpy.concatenate([X_train[idx], labels])\n",
    "    noise = random_input_batch_with_class(labels)\n",
    "    gen_imgs = generator_model.predict(noise)\n",
    "\n",
    "    d_loss_real = discriminator_model.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "    d_loss_fake = discriminator_model.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    noise = random_input_batch_with_class(np.concatenate([labels, labels]))\n",
    "    g_loss = double_model.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "    print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
