{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ganimedes/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "\n",
    "input_encoder = Input(shape=(28, 28, 1))\n",
    "input_decoder = Input(shape=(4, 4, 4))\n",
    "\n",
    "\n",
    "def custom_activation(x):\n",
    "    return (K.sigmoid(x) * 3) \n",
    "\n",
    "with open('decoder.json', 'r') as f:\n",
    "    decoder = model_from_json(f.read())\n",
    "    decoder.load_weights(\"decoder.h5\")\n",
    "    \n",
    "with open('encoder.json', 'r') as f:\n",
    "    encoder = model_from_json(f.read())\n",
    "    encoder.load_weights(\"encoder.h5\")\n",
    "    \n",
    "with open('autoencoder.json', 'r') as f:\n",
    "    autoencoder = model_from_json(f.read())\n",
    "    autoencoder.load_weights(\"autoencoder.h5\")\n",
    "    \n",
    "with open('generator.json', 'r') as f:\n",
    "    generator = model_from_json(f.read(), {'custom_activation': custom_activation})\n",
    "    generator.load_weights(\"generator.h5\")\n",
    "\n",
    "with open('discriminator.json', 'r') as f:\n",
    "    discriminator = model_from_json(f.read())\n",
    "    discriminator.load_weights(\"discriminator.h5\")\n",
    "    \n",
    "generator_per_class = []\n",
    "discriminator_per_class = []\n",
    "for _class in range(10):\n",
    "    with open('models/generator%s.json' % str(_class), 'r') as f:\n",
    "        generatora = model_from_json(f.read(), {'custom_activation': custom_activation})\n",
    "        generatora.load_weights(\"models/generator%s.h5\" % str(_class))\n",
    "        generator_per_class.append(generatora)\n",
    "\n",
    "    with open('models/discriminator%s.json' % str(_class), 'r') as f:\n",
    "        discriminatora = model_from_json(f.read())\n",
    "        discriminatora.load_weights(\"models/discriminator%s.h5\" % str(_class))\n",
    "        discriminator_per_class.append(discriminatora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "\n",
    "x_train = encoder.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 4, 4, 4)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import mixture\n",
    "\n",
    "(x_train, y_train), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "\n",
    "x_train = encoder.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 4, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import mixture\n",
    "\n",
    "(x_train, y_train), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "\n",
    "x_train = encoder.predict(x_train)\n",
    "\n",
    "data_gmm = x_train.reshape(x_train.shape[0], -1)\n",
    "\n",
    "gmm_model = []\n",
    "for i in range(10):\n",
    "    gmm_model.append(mixture.GaussianMixture(n_components=10, covariance_type='full'))\n",
    "    result = []\n",
    "    for a, b in zip(data_gmm, y_train):\n",
    "        if b == i:\n",
    "            result.append(a)\n",
    "    data_train = np.array(result)\n",
    "    gmm_model[i].fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_generator(samples_count, class_type):\n",
    "    a = gmm_model[class_type].sample(samples_count)\n",
    "    sample = np.array(a[0])\n",
    "    return sample\n",
    "\n",
    "\n",
    "def cluster_per_feature_class_generator(samples_count, class_type):\n",
    "    data = x_train.reshape(x_train.shape[0], -1)\n",
    "    result = []\n",
    "    for a, b in zip(data, y_train):\n",
    "        if b == class_type:\n",
    "            result.append(a)\n",
    "    data = np.array(result).T\n",
    "    result = []\n",
    "    for a in data:\n",
    "        result.append(np.random.choice(a, samples_count))\n",
    "    result = np.array(result)\n",
    "    result = result.T\n",
    "    return result\n",
    "            \n",
    "def cluster_per_feature_generator(samples_count):\n",
    "    data = x_train.reshape(x_train.shape[0], -1)\n",
    "    data = data.T\n",
    "    result = []\n",
    "    for a in data:\n",
    "        result.append(np.random.choice(a, samples_count))\n",
    "    result = np.array(result)\n",
    "    result = result.T\n",
    "    return result\n",
    "\n",
    "def generate_per_class(samples_count, class_type):\n",
    "    return generator_per_class[class_type].predict(np.random.normal(0, 1, (samples_count, 100)))\n",
    "\n",
    "def discriminator_vote(samples):\n",
    "    #(batch, 64)\n",
    "    temp = []\n",
    "    for disc in discriminator_per_class:\n",
    "        prediction = disc.predict(samples)\n",
    "        prediction = np.round(prediction, 0)\n",
    "        temp.append(prediction)\n",
    "    temp = np.array(temp)\n",
    "    temp = temp.T.reshape(-1, 10)\n",
    "    print(temp.shape)\n",
    "    result = []\n",
    "    for row in temp:\n",
    "        if np.sum(row) == 0:\n",
    "            result.append(0)\n",
    "        else:\n",
    "            result.append(1)\n",
    "    return np.array(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_count = 5\n",
    "\n",
    "real_x = x_train.reshape(x_train.shape[0], -1)\n",
    "\n",
    "def prepare_data_same_ratio_of_generators(dim):\n",
    "    samples_per_generator_count = dim // generator_count\n",
    "    data_x = np.concatenate([real_x[:samples_per_generator_count], generator.predict(np.random.normal(0, 1, (samples_per_generator_count, 100)))])\n",
    "    for _class in range(10):\n",
    "        data_x = np.concatenate([data_x, gmm_generator(samples_per_generator_count // 10, _class), cluster_per_feature_class_generator(samples_per_generator_count // 10, _class), generate_per_class(samples_per_generator_count // 10, _class)])\n",
    "    data_y = np.concatenate([np.ones(samples_per_generator_count), np.zeros((generator_count - 1)*samples_per_generator_count)])\n",
    "    s = np.arange(data_x.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    return data_x[s], data_y[s]\n",
    "\n",
    "def prepare_data_same_count_of_fakes_to_real(dim):\n",
    "    samples_per_generator_count = (dim // 2) // (generator_count - 1)\n",
    "    data_x = np.concatenate([real_x[:dim // 2], generator.predict(np.random.normal(0, 1, (samples_per_generator_count, 100)))])\n",
    "    for _class in range(10):\n",
    "        data_x = np.concatenate([data_x, gmm_generator(samples_per_generator_count // 10, _class), cluster_per_feature_class_generator(samples_per_generator_count // 10, _class), generate_per_class(samples_per_generator_count // 10, _class)])\n",
    "    data_y = np.concatenate([np.ones(dim // 2), np.zeros(dim // 2)])\n",
    "    s = np.arange(data_x.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    return data_x[s], data_y[s]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = prepare_data_same_ratio_of_generators(50000)\n",
    "validate_x, validate_y = prepare_data_same_ratio_of_generators(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(train_x, train_y)\n",
    "predictions = clf.predict(validate_x)\n",
    "print(accuracy_score(validate_y, predictions))\n",
    "print(confusion_matrix(validate_y, predictions))\n",
    "print(classification_report(validate_y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = discriminator_vote(validate_x)\n",
    "print(accuracy_score(validate_y, predictions))\n",
    "print(confusion_matrix(validate_y, predictions))\n",
    "print(classification_report(validate_y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = prepare_data_same_count_of_fakes_to_real(80000)\n",
    "validate_x, validate_y = prepare_data_same_count_of_fakes_to_real(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]0.7133\n",
      "[[2554 2446]\n",
      " [ 421 4579]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.86      0.51      0.64      5000\n",
      "        1.0       0.65      0.92      0.76      5000\n",
      "\n",
      "avg / total       0.76      0.71      0.70     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "clf = SVC(verbose=True)\n",
    "clf.fit(train_x, train_y)\n",
    "predictions = clf.predict(validate_x)\n",
    "print(accuracy_score(validate_y, predictions))\n",
    "print(confusion_matrix(validate_y, predictions))\n",
    "print(classification_report(validate_y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "(10000,)\n",
      "0.5619\n",
      "[[ 661 4339]\n",
      " [  42 4958]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.13      0.23      5000\n",
      "        1.0       0.53      0.99      0.69      5000\n",
      "\n",
      "avg / total       0.74      0.56      0.46     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = discriminator_vote(validate_x).reshape(-1)\n",
    "print(predictions.shape)\n",
    "print(accuracy_score(validate_y, predictions))\n",
    "print(confusion_matrix(validate_y, predictions))\n",
    "print(classification_report(validate_y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "80000/80000 [==============================] - 5s - loss: 0.5478 - val_loss: 0.5100\n",
      "Epoch 2/30\n",
      "80000/80000 [==============================] - 6s - loss: 0.5010 - val_loss: 0.4853\n",
      "Epoch 3/30\n",
      "80000/80000 [==============================] - 5s - loss: 0.4736 - val_loss: 0.4978\n",
      "Epoch 4/30\n",
      "80000/80000 [==============================] - 5s - loss: 0.4555 - val_loss: 0.4472\n",
      "Epoch 5/30\n",
      "80000/80000 [==============================] - 5s - loss: 0.4382 - val_loss: 0.4402\n",
      "Epoch 6/30\n",
      "80000/80000 [==============================] - 5s - loss: 0.4222 - val_loss: 0.4241\n",
      "Epoch 7/30\n",
      "80000/80000 [==============================] - 6s - loss: 0.4083 - val_loss: 0.4403\n",
      "Epoch 8/30\n",
      "80000/80000 [==============================] - 6s - loss: 0.3967 - val_loss: 0.3922\n",
      "Epoch 9/30\n",
      "80000/80000 [==============================] - 6s - loss: 0.3851 - val_loss: 0.3849\n",
      "Epoch 10/30\n",
      "80000/80000 [==============================] - 5s - loss: 0.3715 - val_loss: 0.3911\n",
      "Epoch 11/30\n",
      "80000/80000 [==============================] - 5s - loss: 0.3617 - val_loss: 0.3768\n",
      "Epoch 12/30\n",
      "80000/80000 [==============================] - 6s - loss: 0.3508 - val_loss: 0.3503\n",
      "Epoch 13/30\n",
      "80000/80000 [==============================] - 6s - loss: 0.3404 - val_loss: 0.3499\n",
      "Epoch 14/30\n",
      "80000/80000 [==============================] - 5s - loss: 0.3316 - val_loss: 0.3581\n",
      "Epoch 15/30\n",
      "80000/80000 [==============================] - 6s - loss: 0.3219 - val_loss: 0.3690\n",
      "Epoch 16/30\n",
      "80000/80000 [==============================] - 6s - loss: 0.3136 - val_loss: 0.3402\n",
      "Epoch 17/30\n",
      "80000/80000 [==============================] - 5s - loss: 0.3050 - val_loss: 0.3145\n",
      "Epoch 18/30\n",
      "80000/80000 [==============================] - 6s - loss: 0.2944 - val_loss: 0.3591\n",
      "Epoch 19/30\n",
      "80000/80000 [==============================] - 6s - loss: 0.2873 - val_loss: 0.3317\n",
      "Epoch 20/30\n",
      "80000/80000 [==============================] - 6s - loss: 0.2813 - val_loss: 0.3105\n",
      "Epoch 21/30\n",
      "80000/80000 [==============================] - 6s - loss: 0.2739 - val_loss: 0.3296\n",
      "Epoch 22/30\n",
      "80000/80000 [==============================] - 6s - loss: 0.2652 - val_loss: 0.3254\n",
      "Epoch 23/30\n",
      "80000/80000 [==============================] - 5s - loss: 0.2605 - val_loss: 0.2976\n",
      "Epoch 24/30\n",
      "80000/80000 [==============================] - 6s - loss: 0.2537 - val_loss: 0.2899\n",
      "Epoch 25/30\n",
      "80000/80000 [==============================] - 5s - loss: 0.2472 - val_loss: 0.2682\n",
      "Epoch 26/30\n",
      "80000/80000 [==============================] - 6s - loss: 0.2421 - val_loss: 0.2588\n",
      "Epoch 27/30\n",
      "80000/80000 [==============================] - 6s - loss: 0.2342 - val_loss: 0.2672\n",
      "Epoch 28/30\n",
      "80000/80000 [==============================] - 6s - loss: 0.2291 - val_loss: 0.2586\n",
      "Epoch 29/30\n",
      "80000/80000 [==============================] - 5s - loss: 0.2242 - val_loss: 0.2536\n",
      "Epoch 30/30\n",
      "80000/80000 [==============================] - 5s - loss: 0.2177 - val_loss: 0.3059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1df90483c8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = discriminator\n",
    "clf.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "clf.fit(train_x, train_y,\n",
    "                epochs=30,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(validate_x, validate_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(validate_x)\n",
    "predictions = np.round(predictions, 0)\n",
    "print(accuracy_score(validate_y, predictions))\n",
    "print(confusion_matrix(validate_y, predictions))\n",
    "print(classification_report(validate_y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(train_x, train_y)\n",
    "predictions = clf.predict(validate_x)\n",
    "print(accuracy_score(validate_y, predictions))\n",
    "print(confusion_matrix(validate_y, predictions))\n",
    "print(classification_report(validate_y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen1 = generator.predict(np.random.normal(0, 1, (10000, 100)))\n",
    "gen2 = cluster_per_feature_generator(10000)\n",
    "gen3 = gmm_generator(1000, 9)\n",
    "gen4 = cluster_per_feature_class_generator(1000, 9)\n",
    "gen5 = generate_per_class(1000, 9)\n",
    "for a in range(9):\n",
    "    gen3 = np.concatenate([gen3, gmm_generator(1000, a)])\n",
    "    gen4 = np.concatenate([gen4, cluster_per_feature_class_generator(1000, a)])\n",
    "    gen5 = np.concatenate([gen3, generate_per_class(1000, a)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9994\n"
     ]
    }
   ],
   "source": [
    "result = clf.predict(gen2)\n",
    "result = np.round(result, 0)\n",
    "count = 0\n",
    "for a in result:\n",
    "    if a == 0:\n",
    "        count = count + 1\n",
    "print(count / result.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.526\n"
     ]
    }
   ],
   "source": [
    "result = clf.predict(gen3)\n",
    "result = np.round(result, 0)\n",
    "\n",
    "count = 0\n",
    "for a in result:\n",
    "    if a == 0:\n",
    "        count = count + 1\n",
    "print(count / result.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8811\n"
     ]
    }
   ],
   "source": [
    "result = clf.predict(gen1)\n",
    "result = np.round(result, 0)\n",
    "\n",
    "count = 0\n",
    "for a in result:\n",
    "    if a == 0:\n",
    "        count = count + 1\n",
    "print(count / result.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5309090909090909\n"
     ]
    }
   ],
   "source": [
    "result = clf.predict(gen5)\n",
    "result = np.round(result, 0)\n",
    "\n",
    "count = 0\n",
    "for a in result:\n",
    "    if a == 0:\n",
    "        count = count + 1\n",
    "print(count / result.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
