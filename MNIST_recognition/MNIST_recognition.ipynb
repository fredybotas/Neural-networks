{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('../MNIST_data', one_hot=True)\n",
    "\n",
    "input_dim = 28 * 28 # number of pixels in one picture\n",
    "h1_dim = 128 # size of hidden layer\n",
    "output_dim = 10 # number of classes (10 digits)\n",
    "\n",
    "learning_rate = 0.01\n",
    "epoch_range = 5000\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xavier initialization for weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "    return tf.random_normal(shape=size, stddev=xavier_stddev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float32\", shape=[None, input_dim])\n",
    "y = tf.placeholder(\"float32\", shape=[None, output_dim])\n",
    "\n",
    "N_W1 = tf.Variable(xavier_init([input_dim, h1_dim]))\n",
    "N_B1 = tf.Variable(np.zeros(shape=[h1_dim]))\n",
    "N_B1 = tf.cast(N_B1, \"float32\")\n",
    "\n",
    "N_W2 = tf.Variable(xavier_init([h1_dim, output_dim]))\n",
    "N_B2 = tf.Variable(np.zeros(shape=output_dim))\n",
    "N_B2 = tf.cast(N_B2, \"float32\")\n",
    "\n",
    "hidden_layer = tf.nn.sigmoid(tf.matmul(x, N_W1) + N_B1)\n",
    "output_layer = tf.matmul(hidden_layer, N_W2) + N_B2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output_layer, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct prediction model and accuracy measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = tf.equal(tf.argmax(output_layer, 1), tf.argmax(y, 1))\n",
    "prediction = tf.cast(prediction, \"float32\")\n",
    "accuracy = tf.reduce_mean(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training cycle with accuracy output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy 0.1\n",
      "Validation accuracy 0.099\n",
      "Training accuracy 0.84\n",
      "Validation accuracy 0.869\n",
      "Training accuracy 0.9\n",
      "Validation accuracy 0.9006\n",
      "Training accuracy 0.9\n",
      "Validation accuracy 0.9286\n",
      "Training accuracy 0.96\n",
      "Validation accuracy 0.9422\n",
      "Training accuracy 0.9\n",
      "Validation accuracy 0.9374\n",
      "Training accuracy 0.98\n",
      "Validation accuracy 0.9502\n",
      "Training accuracy 0.96\n",
      "Validation accuracy 0.9502\n",
      "Training accuracy 0.94\n",
      "Validation accuracy 0.9502\n",
      "Training accuracy 0.98\n",
      "Validation accuracy 0.9402\n",
      "Training accuracy 0.96\n",
      "Validation accuracy 0.958\n",
      "Training accuracy 0.94\n",
      "Validation accuracy 0.9488\n",
      "Training accuracy 0.96\n",
      "Validation accuracy 0.9628\n",
      "Training accuracy 1.0\n",
      "Validation accuracy 0.9606\n",
      "Training accuracy 0.94\n",
      "Validation accuracy 0.967\n",
      "Training accuracy 0.98\n",
      "Validation accuracy 0.964\n",
      "Training accuracy 0.94\n",
      "Validation accuracy 0.9622\n",
      "Training accuracy 0.96\n",
      "Validation accuracy 0.9626\n",
      "Training accuracy 0.96\n",
      "Validation accuracy 0.969\n",
      "Training accuracy 0.96\n",
      "Validation accuracy 0.9644\n",
      "Training accuracy 0.96\n",
      "Validation accuracy 0.9678\n",
      "Training accuracy 1.0\n",
      "Validation accuracy 0.969\n",
      "Training accuracy 0.98\n",
      "Validation accuracy 0.9676\n",
      "Training accuracy 0.94\n",
      "Validation accuracy 0.9724\n",
      "Training accuracy 0.98\n",
      "Validation accuracy 0.9742\n",
      "Training accuracy 1.0\n",
      "Validation accuracy 0.9718\n",
      "Training accuracy 0.92\n",
      "Validation accuracy 0.969\n",
      "Training accuracy 0.98\n",
      "Validation accuracy 0.9734\n",
      "Training accuracy 0.98\n",
      "Validation accuracy 0.9722\n",
      "Training accuracy 0.98\n",
      "Validation accuracy 0.9688\n",
      "Training accuracy 1.0\n",
      "Validation accuracy 0.97\n",
      "Training accuracy 0.98\n",
      "Validation accuracy 0.9696\n",
      "Training accuracy 0.96\n",
      "Validation accuracy 0.9708\n",
      "Training accuracy 0.98\n",
      "Validation accuracy 0.973\n",
      "Training accuracy 0.94\n",
      "Validation accuracy 0.9666\n",
      "Training accuracy 1.0\n",
      "Validation accuracy 0.9728\n",
      "Training accuracy 0.92\n",
      "Validation accuracy 0.9676\n",
      "Training accuracy 1.0\n",
      "Validation accuracy 0.9716\n",
      "Training accuracy 1.0\n",
      "Validation accuracy 0.9714\n",
      "Training accuracy 0.98\n",
      "Validation accuracy 0.9712\n",
      "Training accuracy 1.0\n",
      "Validation accuracy 0.972\n",
      "Training accuracy 0.96\n",
      "Validation accuracy 0.9712\n",
      "Training accuracy 0.96\n",
      "Validation accuracy 0.9728\n",
      "Training accuracy 0.98\n",
      "Validation accuracy 0.969\n",
      "Training accuracy 1.0\n",
      "Validation accuracy 0.9676\n",
      "Training accuracy 1.0\n",
      "Validation accuracy 0.9722\n",
      "Training accuracy 0.96\n",
      "Validation accuracy 0.9728\n",
      "Training accuracy 0.96\n",
      "Validation accuracy 0.9758\n",
      "Training accuracy 1.0\n",
      "Validation accuracy 0.9738\n",
      "Training accuracy 0.92\n",
      "Validation accuracy 0.9686\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(epoch_range):\n",
    "    batch_x, batch_y = mnist.train.next_batch(batch_size=batch_size)\n",
    "    if epoch % 100 == 0:\n",
    "        training = accuracy.eval({x: batch_x, y:batch_y})\n",
    "        validation = accuracy.eval({x: mnist.validation.images, y:mnist.validation.labels})\n",
    "        print(\"Training accuracy \" + str(training))\n",
    "        print(\"Validation accuracy \" + str(validation))\n",
    "\n",
    "    sess.run([optimizer, loss], feed_dict={x:batch_x, y:batch_y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to predict a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADIhJREFUeJzt3WGoXOWdx/HfL7HxRRoh2cxeQhq93SqKCKZ1CAuRtUu3\nxUoxRkQSpKRomiINbKEvFFfQl2HdtgguhXQNjdK1XUijeaG71bAigaU4Cak31nZNww3NJSYTrGhB\nyCb574t7LFe9c+Y658ycuf6/H7jcM+c55zl/Dvd3z8w8M+dxRAhAPkuaLgBAMwg/kBThB5Ii/EBS\nhB9IivADSRF+ICnCDyRF+IGkLhvlwVavXh2Tk5OjPCSQyvT0tM6dO+eFbFsp/LZvlfS4pKWS/i0i\ndpVtPzk5qU6nU+WQAEq02+0Fbzvw037bSyX9q6SvS7pe0lbb1w/aH4DRqvKaf4Ok4xFxIiLOS/q5\npE31lAVg2KqEf62kP855fKpY9yG2d9ju2O50u90KhwNQp6G/2x8RuyOiHRHtVqs17MMBWKAq4Z+R\ntG7O488V6wAsAlXC/6qka2x/3vYySVskHainLADDNvBQX0RcsL1T0n9pdqhvT0S8XltlAIaq0jh/\nRDwv6fmaagEwQny8F0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiB\npAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4\ngaQqzdJre1rSe5IuSroQEe06isKnx5EjR3q23XTTTaX77t+/v7T99ttvL21fsoRrW5lK4S/8fUSc\nq6EfACPEv0YgqarhD0m/sn3Y9o46CgIwGlWf9t8cETO2/1rSi7Z/FxGvzN2g+KewQ5KuvPLKiocD\nUJdKV/6ImCl+n5W0X9KGebbZHRHtiGi3Wq0qhwNQo4HDb3u57RUfLEv6mqRjdRUGYLiqPO2fkLTf\n9gf9/HtE/GctVQEYuoHDHxEnJN1YYy1YhN5///3S9jvvvHPgvjdv3lzafv78+dJ2xvnLcXaApAg/\nkBThB5Ii/EBShB9IivADSdXxrT4kNjU1Vdp+8uTJgfveuXNnaftll/HnWwVXfiApwg8kRfiBpAg/\nkBThB5Ii/EBShB9IioFSlLpw4UJp+wMPPDC0Y2/fvr20vbiXBAbElR9IivADSRF+ICnCDyRF+IGk\nCD+QFOEHkmKcH6VmZmZK219++eWB++73ffwbb+TO8MPElR9IivADSRF+ICnCDyRF+IGkCD+QFOEH\nkuo7zm97j6RvSDobETcU61ZJ+oWkSUnTku6OiD8Nr0w0Zd++fUPre8uWLUPrG/0t5Mr/U0m3fmTd\ng5IORsQ1kg4WjwEsIn3DHxGvSHr7I6s3SdpbLO+VdEfNdQEYskFf809ExOli+S1JEzXVA2BEKr/h\nFxEhKXq1295hu2O70+12qx4OQE0GDf8Z22skqfh9tteGEbE7ItoR0W61WgMeDkDdBg3/AUnbiuVt\nkp6rpxwAo9I3/LafkfQ/kq61fcr2fZJ2Sfqq7Tcl/UPxGMAi0necPyK29mj6Ss21YAy99NJLlfZf\ntmxZz7Zdu7hmNIlP+AFJEX4gKcIPJEX4gaQIP5AU4QeS4tbdyZ04caK0/YUXXqjU/4oVK3q2rV27\ntlLfqIYrP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kxTh/cocPHx5q/w8//PBQ+8fguPIDSRF+ICnC\nDyRF+IGkCD+QFOEHkiL8QFKM8yd36NChSvuvWrWqtP3ee++t1D+Ghys/kBThB5Ii/EBShB9IivAD\nSRF+ICnCDyTVd5zf9h5J35B0NiJuKNY9KunbkrrFZg9FxPPDKhKDO378eGn7E088Uan/lStXlrZf\nccUVlfrH8Czkyv9TSbfOs/5HEbG++CH4wCLTN/wR8Yqkt0dQC4ARqvKaf6ft12zvsV3+3A/A2Bk0\n/D+W9AVJ6yWdlvSDXhva3mG7Y7vT7XZ7bQZgxAYKf0SciYiLEXFJ0k8kbSjZdndEtCOi3Wq1Bq0T\nQM0GCr/tNXMebpZ0rJ5yAIzKQob6npH0ZUmrbZ+S9IikL9teLykkTUv6zhBrBDAEfcMfEVvnWf3k\nEGrBELzzzjul7ZcuXarU/1133VVpfzSHT/gBSRF+ICnCDyRF+IGkCD+QFOEHkuLW3Z9yTz/9dKX9\n+92a+/7776/UP5rDlR9IivADSRF+ICnCDyRF+IGkCD+QFOEHkmKc/1Pg3Xff7dlW9dbcV199dWn7\nVVddVal/NIcrP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kxTj/p8CxY73nTKl6a+577rmn0v4YX1z5\ngaQIP5AU4QeSIvxAUoQfSIrwA0kRfiCpvuP8ttdJekrShKSQtDsiHre9StIvJE1KmpZ0d0T8aXil\nopdz584NvO/ExERp+/bt2wfuG+NtIVf+C5K+HxHXS/pbSd+1fb2kByUdjIhrJB0sHgNYJPqGPyJO\nR8SRYvk9SW9IWitpk6S9xWZ7Jd0xrCIB1O8Tvea3PSnpi5J+LWkiIk4XTW9p9mUBgEViweG3/VlJ\n+yR9LyI+dNO4iAjNvh8w3347bHdsd7rdbqViAdRnQeG3/RnNBv9nEfHLYvUZ22uK9jWSzs63b0Ts\njoh2RLRbrVYdNQOoQd/w27akJyW9ERE/nNN0QNK2YnmbpOfqLw/AsCzkK70bJX1T0pTto8W6hyTt\nkvQftu+TdFLS3cMpEf08++yzA+977bXXlrZffvnlA/eN8dY3/BFxSJJ7NH+l3nIAjAqf8AOSIvxA\nUoQfSIrwA0kRfiApwg8kxa27F4GLFy+Wtk9NTQ3c9/Lly0vbly5dOnDfGG9c+YGkCD+QFOEHkiL8\nQFKEH0iK8ANJEX4gKcb5F4HZ+6n0dsstt/Rs63Q6pfted911A9WExY8rP5AU4QeSIvxAUoQfSIrw\nA0kRfiApwg8kxTj/IrBkSfn/6EceeaRnW7/PCGzcuHGgmrD4ceUHkiL8QFKEH0iK8ANJEX4gKcIP\nJEX4gaT6jvPbXifpKUkTkkLS7oh43Pajkr4tqVts+lBEPD+sQtHbihUrerY99thjI6wEi8lCPuRz\nQdL3I+KI7RWSDtt+sWj7UUT8y/DKAzAsfcMfEaclnS6W37P9hqS1wy4MwHB9otf8ticlfVHSr4tV\nO22/ZnuP7ZU99tlhu2O70+1259sEQAMWHH7bn5W0T9L3IuJdST+W9AVJ6zX7zOAH8+0XEbsjoh0R\n7VarVUPJAOqwoPDb/oxmg/+ziPilJEXEmYi4GBGXJP1E0obhlQmgbn3D79mvhT0p6Y2I+OGc9Wvm\nbLZZ0rH6ywMwLAt5t3+jpG9KmrJ9tFj3kKStttdrdvhvWtJ3hlIhgKFYyLv9hyTN96VwxvSBRYxP\n+AFJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5JyRIzuYHZX\n0sk5q1ZLOjeyAj6Zca1tXOuSqG1QddZ2VUQs6H55Iw3/xw5udyKi3VgBJca1tnGtS6K2QTVVG0/7\ngaQIP5BU0+Hf3fDxy4xrbeNal0Rtg2qktkZf8wNoTtNXfgANaST8tm+1/Xvbx20/2EQNvdietj1l\n+6jtTsO17LF91vaxOetW2X7R9pvF73mnSWuotkdtzxTn7qjt2xqqbZ3t/7b9W9uv2/7HYn2j566k\nrkbO28if9tteKul/JX1V0ilJr0raGhG/HWkhPdieltSOiMbHhG3/naQ/S3oqIm4o1v2zpLcjYlfx\nj3NlRDwwJrU9KunPTc/cXEwos2buzNKS7pD0LTV47krqulsNnLcmrvwbJB2PiBMRcV7SzyVtaqCO\nsRcRr0h6+yOrN0naWyzv1ewfz8j1qG0sRMTpiDhSLL8n6YOZpRs9dyV1NaKJ8K+V9Mc5j09pvKb8\nDkm/sn3Y9o6mi5nHRDFtuiS9JWmiyWLm0Xfm5lH6yMzSY3PuBpnxum684fdxN0fElyR9XdJ3i6e3\nYylmX7ON03DNgmZuHpV5Zpb+iybP3aAzXtetifDPSFo35/HninVjISJmit9nJe3X+M0+fOaDSVKL\n32cbrucvxmnm5vlmltYYnLtxmvG6ifC/Kuka25+3vUzSFkkHGqjjY2wvL96Ike3lkr6m8Zt9+ICk\nbcXyNknPNVjLh4zLzM29ZpZWw+du7Ga8joiR/0i6TbPv+P9B0j81UUOPuv5G0m+Kn9ebrk3SM5p9\nGvh/mn1v5D5JfyXpoKQ3Jb0kadUY1fa0pClJr2k2aGsaqu1mzT6lf03S0eLntqbPXUldjZw3PuEH\nJMUbfkBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkvp/yg/P3S+u/IkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110432668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_number = mnist.test.images[5]\n",
    "plt.imshow(test_number.reshape(28,28), cmap=\"Greys\");\n",
    "predict = tf.argmax(output_layer, 1)\n",
    "print(predict.eval({x:test_number.reshape(1,28*28)}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}